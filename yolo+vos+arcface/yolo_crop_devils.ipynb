{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954a33cb-c5ca-4192-b990-3dafd276bb4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Path to cropped bodies and JSON file\n",
    "CROPPED_BODY_DIR = r\"D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented\\cropped_bodies_new\"\n",
    "BODY_JSON_PATH = r\"D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented\\body_bboxes.json\"\n",
    "\n",
    "# Load existing JSON\n",
    "with open(BODY_JSON_PATH, 'r') as f:\n",
    "    detections = json.load(f)\n",
    "\n",
    "# Dictionary to store updated detections\n",
    "updated_detections = {}\n",
    "\n",
    "# Process files in cropped body directory\n",
    "for root, _, files in os.walk(CROPPED_BODY_DIR):\n",
    "    for file in files:\n",
    "        if \"_devil_0\" in file and file.endswith('.jpg'):\n",
    "            old_path = os.path.join(root, file)\n",
    "            new_file = file.replace(\"_devil_0\", \"\")\n",
    "            new_path = os.path.join(root, new_file)\n",
    "\n",
    "            # If the new filename already exists, remove it before renaming\n",
    "            if os.path.exists(new_path):\n",
    "                os.remove(new_path)  # Delete existing file to avoid conflict\n",
    "                print(f\"üóëÔ∏è Deleted existing file: {new_path}\")\n",
    "\n",
    "            # Rename the file\n",
    "            os.rename(old_path, new_path)\n",
    "            print(f\"‚úÖ Renamed: {old_path} ‚Üí {new_path}\")\n",
    "\n",
    "            # Update JSON entries\n",
    "            if old_path in detections:\n",
    "                updated_detections[new_path] = detections.pop(old_path)\n",
    "\n",
    "# Save updated JSON\n",
    "with open(BODY_JSON_PATH, 'w') as f:\n",
    "    json.dump(updated_detections, f, indent=4)\n",
    "\n",
    "print(\"\\n‚úÖ Filename cleanup and JSON update completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f7147f-b821-4ebf-a5cf-fb86b69ac600",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80032540-b753-4865-b173-b1f59cc8953b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74df5be2-e0f7-45be-a34a-a19cdcdd8bc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# ------------------------\n",
    "# CONFIGURATION\n",
    "# ------------------------\n",
    "CROPPED_BODY_DIR = r\"D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\cropped_bodies\"\n",
    "MASKS_DIR = r\"D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented\\split_original\"\n",
    "OUTPUT_DIR = r\"D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\"\n",
    "BODY_JSON_PATH = os.path.join(OUTPUT_DIR, \"body_face_bboxes.json\")\n",
    "UPDATED_JSON_PATH = os.path.join(OUTPUT_DIR, \"updated_body_face_bboxes.json\")  # New JSON for body + face info\n",
    "\n",
    "# YOLO Face Model\n",
    "YOLO_FACE_MODEL_PATH = r\"C:\\Users\\Jaylen LI\\yolov8-face\\train\\weights\\best.pt\"\n",
    "\n",
    "# Output directories for cropped & masked faces\n",
    "CROPPED_FACE_DIR = os.path.join(OUTPUT_DIR, \"cropped_faces\")\n",
    "MASKED_FACE_DIR = os.path.join(OUTPUT_DIR, \"masked_faces\")\n",
    "\n",
    "for folder in [CROPPED_FACE_DIR, MASKED_FACE_DIR]:\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "# Load YOLO Face Model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "face_model = YOLO(YOLO_FACE_MODEL_PATH).to(device)\n",
    "\n",
    "# Load existing JSON with body bounding boxes\n",
    "if not os.path.exists(BODY_JSON_PATH):\n",
    "    print(f\"‚ùå ERROR: Missing body JSON: {BODY_JSON_PATH}\")\n",
    "    exit()\n",
    "\n",
    "with open(BODY_JSON_PATH, 'r') as f:\n",
    "    body_detections = json.load(f)\n",
    "\n",
    "# New dictionary to store body + face coordinates relative to original image\n",
    "updated_detections = {}\n",
    "\n",
    "# ------------------------\n",
    "# FUNCTION: Load Mask\n",
    "# ------------------------\n",
    "def load_mask(mask_base_dir, image_path):\n",
    "    \"\"\"Loads a VOS mask and ensures correct path formatting.\"\"\"\n",
    "    subfolder = os.path.basename(os.path.dirname(image_path))  # Extracts subfolder name\n",
    "    mask_path = os.path.join(mask_base_dir, subfolder, Path(image_path).stem + \".png\")\n",
    "\n",
    "    if not os.path.exists(mask_path):\n",
    "        print(f\"‚ö†Ô∏è Warning: Mask file not found: {mask_path}\")\n",
    "        return None\n",
    "\n",
    "    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if mask is None:\n",
    "        print(f\"‚ö†Ô∏è Warning: Failed to load mask: {mask_path}\")\n",
    "        return None\n",
    "    return (mask > 0).astype(np.uint8)  # Convert to binary mask\n",
    "\n",
    "# ------------------------\n",
    "# FUNCTION: Detect & Crop Faces with Corrected Coordinates\n",
    "# ------------------------\n",
    "def detect_and_crop_faces():\n",
    "    \"\"\"Detects faces from already cropped body images and maps them back to original coordinates.\"\"\"\n",
    "    \n",
    "    print(\"\\nüü¢ Starting Face Cropping & JSON Update...\")\n",
    "\n",
    "    for cropped_body_path, metadata in tqdm(body_detections.items()):\n",
    "        image = cv2.imread(cropped_body_path)\n",
    "        original_image_path = metadata[\"original_image\"]\n",
    "        body_bbox = metadata[\"bbox\"]  # Bounding box of body in original image\n",
    "\n",
    "        if image is None:\n",
    "            print(f\"‚ùå Error loading {cropped_body_path}\")\n",
    "            continue\n",
    "\n",
    "        # YOLO Face Detection\n",
    "        img_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = face_model.predict(source=img_rgb, imgsz=640)\n",
    "        predictions = results[0].boxes.data.cpu().numpy()\n",
    "\n",
    "        if len(predictions) == 0:\n",
    "            print(f\"‚ö†Ô∏è No face detected for {cropped_body_path}\")\n",
    "            continue  \n",
    "\n",
    "        for pred in predictions:\n",
    "            x1_face, y1_face, x2_face, y2_face, conf, cls = pred[:6]\n",
    "\n",
    "            print(f\"üîç Face detected in {cropped_body_path} with confidence {conf:.2f}\")\n",
    "\n",
    "            if conf < 0.5:\n",
    "                print(f\"‚ö†Ô∏è Confidence too low ({conf:.2f}), skipping {cropped_body_path}\")\n",
    "                continue\n",
    "\n",
    "            # Convert face bbox from body image space ‚Üí original full image space\n",
    "            x1_face_global = int(body_bbox[0] + x1_face)\n",
    "            y1_face_global = int(body_bbox[1] + y1_face)\n",
    "            x2_face_global = int(body_bbox[0] + x2_face)\n",
    "            y2_face_global = int(body_bbox[1] + y2_face)\n",
    "\n",
    "            # Preserve dataset structure in output\n",
    "            relative_body_path = os.path.relpath(cropped_body_path, CROPPED_BODY_DIR)\n",
    "            output_face_dir = os.path.join(CROPPED_FACE_DIR, os.path.dirname(relative_body_path))\n",
    "            os.makedirs(output_face_dir, exist_ok=True)\n",
    "\n",
    "            output_face_file = os.path.join(output_face_dir, Path(cropped_body_path).stem + \"_face.jpg\")\n",
    "            cv2.imwrite(output_face_file, image[int(y1_face):int(y2_face), int(x1_face):int(x2_face)])\n",
    "\n",
    "            print(f\"‚úÖ Saved cropped face: {output_face_file}\")  \n",
    "\n",
    "            # Load the correct mask from original image path\n",
    "            mask = load_mask(MASKS_DIR, original_image_path)\n",
    "\n",
    "            if mask is not None:\n",
    "                mask_face = np.zeros_like(image[int(y1_face):int(y2_face), int(x1_face):int(x2_face)])\n",
    "                mask_roi = mask[y1_face_global:y2_face_global, x1_face_global:x2_face_global]\n",
    "                mask_face[mask_roi > 0] = image[y1_face:y2_face, x1_face:x2_face][mask_roi > 0]\n",
    "\n",
    "                output_masked_face_dir = os.path.join(MASKED_FACE_DIR, os.path.dirname(relative_body_path))\n",
    "                os.makedirs(output_masked_face_dir, exist_ok=True)\n",
    "\n",
    "                masked_output_face = os.path.join(output_masked_face_dir, Path(cropped_body_path).stem + \"_face.jpg\")\n",
    "                cv2.imwrite(masked_output_face, mask_face)\n",
    "\n",
    "                print(f\"‚úÖ Saved masked face: {masked_output_face}\")\n",
    "\n",
    "            # Update JSON with face coordinates mapped back to original image\n",
    "            updated_detections[output_face_file] = {\n",
    "                \"original_image\": original_image_path,\n",
    "                \"bbox_body\": body_bbox,\n",
    "                \"bbox_face\": [x1_face_global, y1_face_global, x2_face_global, y2_face_global]\n",
    "            }\n",
    "            print(f\"‚úÖ Adding to JSON: {output_face_file} -> {x1_face_global, y1_face_global, x2_face_global, y2_face_global}\")\n",
    "\n",
    "    updated_json_path = os.path.join(OUTPUT_DIR, \"updated_body_face_bboxes.json\")\n",
    "    with open(updated_json_path, 'w') as f:\n",
    "        json.dump(updated_detections, f, indent=4)\n",
    "\n",
    "    print(\"\\n‚úÖ Face Cropping & JSON Update Completed!\")\n",
    "\n",
    "# ------------------------\n",
    "# EXECUTION\n",
    "# ------------------------\n",
    "detect_and_crop_faces()\n",
    "\n",
    "print(\"\\n‚úÖ Face detection completed with JSON update for original coordinates!\")\n",
    "#working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f418a39c-da6a-46f5-a356-0b71001e948d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ------------------------\n",
    "# CONFIGURATION\n",
    "# ------------------------\n",
    "BASE_DIR = r\"D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented\\split_original\"\n",
    "MASKS_DIR = BASE_DIR  # Ensure masks are in the same structure\n",
    "\n",
    "CROPPED_FACE_DIR = r\"D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\cropped_faces\"\n",
    "MASKED_FACE_DIR = r\"D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_faces\"\n",
    "os.makedirs(MASKED_FACE_DIR, exist_ok=True)\n",
    "\n",
    "# ‚úÖ FIXED JSON PATH\n",
    "JSON_PATH = r\"D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\updated_body_face_bboxes.json\"\n",
    "\n",
    "# ------------------------\n",
    "# FUNCTION: Load Mask\n",
    "# ------------------------\n",
    "def load_mask(mask_path):\n",
    "    \"\"\"Loads a VOS mask as a binary numpy array.\"\"\"\n",
    "    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if mask is None:\n",
    "        return None\n",
    "    return (mask > 0).astype(np.uint8)  # Convert to binary mask\n",
    "\n",
    "# ------------------------\n",
    "# FUNCTION: Apply Mask to Cropped Face\n",
    "# ------------------------\n",
    "def apply_mask_to_faces():\n",
    "    \"\"\"Applies the corresponding VOS mask to each cropped face.\"\"\"\n",
    "    \n",
    "    # ‚úÖ Check if JSON exists\n",
    "    if not os.path.exists(JSON_PATH):\n",
    "        print(f\"‚ùå ERROR: JSON file not found: {JSON_PATH}\")\n",
    "        return\n",
    "\n",
    "    # Load bounding box data\n",
    "    with open(JSON_PATH, 'r') as f:\n",
    "        detections = json.load(f)\n",
    "\n",
    "    if not detections:\n",
    "        print(f\"‚ùå ERROR: JSON file is empty: {JSON_PATH}\")\n",
    "        return\n",
    "\n",
    "    for face_image_path, metadata in tqdm(detections.items()):\n",
    "        original_image_path = metadata[\"original_image\"]\n",
    "        bbox_face = metadata[\"bbox_face\"]\n",
    "\n",
    "        # Load face image\n",
    "        face_image = cv2.imread(face_image_path)\n",
    "        if face_image is None:\n",
    "            print(f\"‚ùå Error loading {face_image_path}\")\n",
    "            continue\n",
    "        \n",
    "        # Load corresponding mask\n",
    "        mask_path = original_image_path.replace(\"images\", \"masks\").replace(\".jpg\", \".png\")\n",
    "        mask = load_mask(mask_path)\n",
    "        if mask is None:\n",
    "            print(f\"‚ö†Ô∏è No mask found for {original_image_path}, skipping mask application.\")\n",
    "            continue\n",
    "\n",
    "        # Extract face bounding box coordinates\n",
    "        x1, y1, x2, y2 = bbox_face\n",
    "        mask_face = mask[y1:y2, x1:x2]\n",
    "\n",
    "        if mask_face.shape[:2] != face_image.shape[:2]:\n",
    "            print(f\"‚ö†Ô∏è Mask size mismatch for {face_image_path}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Apply Mask\n",
    "        masked_face = np.zeros_like(face_image)\n",
    "        masked_face[mask_face > 0] = face_image[mask_face > 0]\n",
    "\n",
    "        # Save Masked Face\n",
    "        output_file = face_image_path.replace(CROPPED_FACE_DIR, MASKED_FACE_DIR)\n",
    "        os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "        cv2.imwrite(output_file, masked_face)\n",
    "\n",
    "        print(f\"‚úÖ Mask applied: {output_file}\")\n",
    "\n",
    "# ------------------------\n",
    "# EXECUTION\n",
    "# ------------------------\n",
    "apply_mask_to_faces()\n",
    "print(\"\\n‚úÖ Masking process for cropped faces completed!\")\n",
    "#working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4448fd4-3df2-4ead-ae7d-95cc5efbfed5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO  # Ensure Ultralytics package is installed\n",
    "\n",
    "# ------------------------\n",
    "# CONFIGURATION\n",
    "# ------------------------\n",
    "OUTPUT_DIR = r\"D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\"\n",
    "FINAL_JSON_PATH = os.path.join(OUTPUT_DIR, \"test_body_face_bboxes.json\")  # JSON for test set bounding boxes\n",
    "\n",
    "# YOLO Face Model\n",
    "YOLO_FACE_MODEL_PATH = r\"C:\\Users\\Jaylen LI\\yolov8-face\\train\\weights\\best.pt\"\n",
    "\n",
    "# Ensure directories exist\n",
    "CROPPED_BODY_DIR = os.path.join(OUTPUT_DIR, \"cropped_bodies\", \"test\")  # Input for face cropping\n",
    "CROPPED_FACE_DIR = os.path.join(OUTPUT_DIR, \"cropped_faces\", \"test\")   # Output for cropped faces\n",
    "MASKED_FACE_DIR = os.path.join(OUTPUT_DIR, \"masked_faces\", \"test\")     # Output for masked faces\n",
    "\n",
    "for folder in [CROPPED_FACE_DIR, MASKED_FACE_DIR]:\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "# Load YOLO Face Model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "face_model = YOLO(YOLO_FACE_MODEL_PATH).to(device)\n",
    "\n",
    "# ------------------------\n",
    "# FUNCTION: Detect & Crop Faces (TEST SET)\n",
    "# ------------------------\n",
    "def detect_and_crop_test_faces():\n",
    "    \"\"\"Detects faces using YOLOv8 on already cropped full-body test images.\"\"\"\n",
    "    \n",
    "    print(\"\\nüîç Processing Test Set for Face Detection...\")\n",
    "    \n",
    "    # Load existing JSON with body bounding boxes\n",
    "    if not os.path.exists(FINAL_JSON_PATH):\n",
    "        print(f\"‚ùå ERROR: Missing test JSON file: {FINAL_JSON_PATH}. Run body detection first!\")\n",
    "        return\n",
    "\n",
    "    with open(FINAL_JSON_PATH, 'r') as f:\n",
    "        body_detections = json.load(f)\n",
    "\n",
    "    face_detections = {}\n",
    "    \n",
    "    for cropped_body_path, metadata in tqdm(body_detections.items()):\n",
    "        image = cv2.imread(cropped_body_path)\n",
    "        original_image_path = metadata[\"original_image\"]\n",
    "        body_bbox = metadata[\"bbox\"]  # Bounding box of body in original image\n",
    "\n",
    "        if image is None:\n",
    "            print(f\"‚ùå Error loading {cropped_body_path}\")\n",
    "            continue\n",
    "\n",
    "        # YOLO Face Detection\n",
    "        img_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = face_model.predict(source=img_rgb, imgsz=640)\n",
    "        predictions = results[0].boxes.data.cpu().numpy()\n",
    "\n",
    "        if len(predictions) == 0:\n",
    "            print(f\"‚ö†Ô∏è No face detected in {cropped_body_path}\")\n",
    "            continue  \n",
    "\n",
    "        object_count = 0\n",
    "        for pred in predictions:\n",
    "            x1_face, y1_face, x2_face, y2_face, conf, cls = pred[:6]\n",
    "\n",
    "            print(f\"üîç Face detected in {cropped_body_path} with confidence {conf:.2f}\")\n",
    "\n",
    "            if conf < 0.3:  # Lower threshold for test set\n",
    "                print(f\"‚ö†Ô∏è Confidence too low ({conf:.2f}), skipping {cropped_body_path}\")\n",
    "                continue\n",
    "\n",
    "            cropped_face = image[int(y1_face):int(y2_face), int(x1_face):int(x2_face)]\n",
    "            if cropped_face.size == 0:\n",
    "                print(f\"‚ùå Invalid face crop for {cropped_body_path}, skipping.\")\n",
    "                continue\n",
    "\n",
    "            # Preserve dataset structure in output\n",
    "            relative_body_path = os.path.relpath(cropped_body_path, CROPPED_BODY_DIR)\n",
    "            output_face_dir = os.path.join(CROPPED_FACE_DIR, os.path.dirname(relative_body_path))\n",
    "            os.makedirs(output_face_dir, exist_ok=True)\n",
    "\n",
    "            output_face_file = os.path.join(output_face_dir, Path(cropped_body_path).stem + \"_face.jpg\")\n",
    "            cv2.imwrite(output_face_file, cropped_face)\n",
    "\n",
    "            print(f\"‚úÖ Saved cropped face: {output_face_file}\")  \n",
    "\n",
    "            # Convert face bbox from body image space ‚Üí original full image space\n",
    "            x1_face_global = int(body_bbox[0] + x1_face)\n",
    "            y1_face_global = int(body_bbox[1] + y1_face)\n",
    "            x2_face_global = int(body_bbox[0] + x2_face)\n",
    "            y2_face_global = int(body_bbox[1] + y2_face)\n",
    "\n",
    "            # Update JSON with face coordinates mapped back to original image\n",
    "            face_detections[output_face_file] = {\n",
    "                \"original_image\": original_image_path,\n",
    "                \"bbox_body\": body_bbox,\n",
    "                \"bbox_face\": [x1_face_global, y1_face_global, x2_face_global, y2_face_global]\n",
    "            }\n",
    "\n",
    "    # Save updated JSON with face coordinates\n",
    "    updated_json_path = os.path.join(OUTPUT_DIR, \"test_face_bboxes.json\")\n",
    "    with open(updated_json_path, 'w') as f:\n",
    "        json.dump(face_detections, f, indent=4)\n",
    "\n",
    "    print(f\"\\n‚úÖ Face Cropping Completed! JSON saved: {updated_json_path}\")\n",
    "\n",
    "# ------------------------\n",
    "# EXECUTION\n",
    "# ------------------------\n",
    "detect_and_crop_test_faces()\n",
    "\n",
    "print(\"\\n‚úÖ Test Set Face Detection & Cropping Completed!\")\n",
    "#working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2cc83758-c32b-4e28-9c91-c8c2dbd08b70",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Applying VOS masks to cropped bodies...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|‚ñà‚ñà‚ñà‚ñà‚ñè                                                                             | 6/116 [00:00<00:01, 57.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Case\\frame_0004_5421_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Chev\\frame_0000_5417_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Chev\\frame_0003_5417_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Chev\\frame_0004_5417_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Chev\\frame_0010_5417_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Chev\\frame_0034_5417_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Chev\\frame_0035_5417_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Colet\\frame_0001_5394_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Colet\\frame_0008_5394_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Colet\\frame_0010_5394_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Colet\\frame_0011_5394_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Colet\\frame_0031_5394_body.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                   | 20/116 [00:00<00:01, 64.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Colet\\frame_0033_5394_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\DarrenHayes\\frame_0010_0001_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Dart\\frame_0002_5403_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Dart\\frame_0002_5458_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Dart\\frame_0005_5458_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Dart\\frame_0007_5458_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Dart\\frame_0008_5458_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Dart\\frame_0011_5458_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Dart\\frame_0012_5458_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Dart\\frame_0013_5458_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Dart\\frame_0014_5403_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Dart\\frame_0023_5458_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Dart\\frame_0026_5458_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Diamond T\\frame_0003_5401_body.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                    | 41/116 [00:00<00:01, 66.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Diamond T\\frame_0012_5401_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Diamond T\\frame_0014_5401_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Diamond T\\frame_0015_5401_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Diamond T\\frame_0023_5401_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Fageol\\frame_0005_5404_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Fageol\\frame_0009_5404_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Fageol\\frame_0019_5404_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Fageol\\frame_0041_5404_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Fageol\\frame_0046_5404_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Fageol\\frame_0050_5404_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Fiat\\frame_0003_5459_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Fiat\\frame_0004_5413_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Fiat\\frame_0009_5459_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Fiat\\frame_0013_5459_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Fiat\\frame_0020_5459_body.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                               | 48/116 [00:00<00:01, 63.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Fiat\\frame_0027_5413_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Fiat\\frame_0028_5413_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Freeman\\frame_0002_5468_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Freeman\\frame_0004_5380_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Freeman\\frame_0008_5380_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Freeman\\frame_0009_5380_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Freeman\\frame_0010_5380_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Freeman\\frame_0012_5468_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Freeman\\frame_0015_5468_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Gersix\\frame_0000_5396_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Gersix\\frame_0009_5396_body.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                     | 62/116 [00:00<00:00, 62.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Gersix\\frame_0011_5396_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Gersix\\frame_0016_5396_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Gersix\\frame_0022_5396_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Gersix\\frame_0024_5396_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Hayes\\frame_0003_5392_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Hayes\\frame_0011_5392_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Hayes\\frame_0013_5392_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\John Dere (Deere)\\frame_0000_5481_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\John Dere (Deere)\\frame_0003_5481_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\John Dere (Deere)\\frame_0004_5407_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\John Dere (Deere)\\frame_0005_5481_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\John Dere (Deere)\\frame_0006_5407_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\John Dere (Deere)\\frame_0007_5407_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\John Dere (Deere)\\frame_0010_5407_body.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                           | 77/116 [00:01<00:00, 65.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\John Dere (Deere)\\frame_0012_5481_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\John Dere (Deere)\\frame_0033_5407_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Jowett\\frame_0001_5446_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Jowett\\frame_0002_5457_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Jowett\\frame_0003_5446_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Jowett\\frame_0007_5446_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Jowett\\frame_0007_5457_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Jowett\\frame_0024_5457_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Jowett\\frame_0034_5446_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Jowett\\frame_0043_5457_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Komatsu\\frame_0006_5428_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Komatsu\\frame_0008_5428_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Komatsu\\frame_0010_5428_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Komatsu\\frame_0036_5428_body.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                 | 91/116 [00:01<00:00, 66.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Komatsu\\frame_0037_5428_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Komatsu\\frame_0040_5428_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Leyland\\frame_0006_5420_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Leyland\\frame_0007_5420_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Leyland\\frame_0021_5420_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Leyland\\frame_0025_5420_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Leyland\\frame_0029_5420_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Manchester\\frame_0003_5467_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Maple Leaf\\frame_0000_5411_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Maple Leaf\\frame_0006_5411_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Maple Leaf\\frame_0007_5411_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Maple Leaf\\frame_0016_5411_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Maple Leaf\\frame_0020_5411_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Maple Leaf\\frame_0021_5411_body.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà       | 106/116 [00:01<00:00, 68.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Maple Leaf\\frame_0024_5411_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Maple Leaf\\frame_0025_5411_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Maple Leaf\\frame_0031_5411_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Maple Leaf\\frame_0033_5411_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Maple Leaf\\frame_0034_5411_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Maple Leaf\\frame_0039_5411_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Maple Leaf\\frame_0040_5411_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Maple Leaf\\frame_0042_5411_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Mezcalita\\frame_0018_0006_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Pacific\\frame_0000_5469_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Pacific\\frame_0012_5469_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Pacific\\frame_0017_5469_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Republic\\frame_0001_5480_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Sentinel\\frame_0001_5474_body.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 116/116 [00:01<00:00, 64.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Sentinel\\frame_0002_5474_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Sentinel\\frame_0008_5474_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Sentinel\\frame_0011_5474_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Sentinel\\frame_0015_5474_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Thornycroft\\frame_0005_5485_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Wallace\\frame_0004_5475_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Wallace\\frame_0008_5475_body.jpg\n",
      "‚úÖ Masked body saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_bodies\\test\\Wallace\\frame_0011_5475_body.jpg\n",
      "\n",
      "üîç Applying VOS masks to cropped faces...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/80 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Masked face saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_faces\\test\\Case\\frame_0004_5421_body_face.jpg\n",
      "‚úÖ Masked face saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_faces\\test\\Chev\\frame_0000_5417_body_face.jpg\n",
      "‚úÖ Masked face saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_faces\\test\\Chev\\frame_0003_5417_body_face.jpg\n",
      "‚úÖ Masked face saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_faces\\test\\Chev\\frame_0004_5417_body_face.jpg\n",
      "‚úÖ Masked face saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_faces\\test\\Chev\\frame_0034_5417_body_face.jpg\n",
      "‚úÖ Masked face saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_faces\\test\\Chev\\frame_0035_5417_body_face.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                                                          | 8/80 [00:00<00:01, 70.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Masked face saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_faces\\test\\Colet\\frame_0001_5394_body_face.jpg\n",
      "‚úÖ Masked face saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_faces\\test\\Colet\\frame_0008_5394_body_face.jpg\n",
      "‚úÖ Masked face saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_faces\\test\\Colet\\frame_0010_5394_body_face.jpg\n",
      "‚úÖ Masked face saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_faces\\test\\Colet\\frame_0011_5394_body_face.jpg\n",
      "‚úÖ Masked face saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_faces\\test\\Colet\\frame_0031_5394_body_face.jpg\n",
      "‚úÖ Masked face saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_faces\\test\\Colet\\frame_0033_5394_body_face.jpg\n",
      "‚úÖ Masked face saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_faces\\test\\Dart\\frame_0002_5403_body_face.jpg\n",
      "‚úÖ Masked face saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_faces\\test\\Dart\\frame_0002_5458_body_face.jpg\n",
      "‚úÖ Masked face saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_faces\\test\\Dart\\frame_0005_5458_body_face.jpg\n",
      "‚úÖ Masked face saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_faces\\test\\Dart\\frame_0007_5458_body_face.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                 | 16/80 [00:00<00:00, 74.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Masked face saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_faces\\test\\Dart\\frame_0008_5458_body_face.jpg\n",
      "‚úÖ Masked face saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_faces\\test\\Dart\\frame_0011_5458_body_face.jpg\n",
      "‚úÖ Masked face saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_faces\\test\\Dart\\frame_0012_5458_body_face.jpg\n",
      "‚úÖ Masked face saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_faces\\test\\Dart\\frame_0013_5458_body_face.jpg\n",
      "‚úÖ Masked face saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_faces\\test\\Dart\\frame_0014_5403_body_face.jpg\n",
      "‚úÖ Masked face saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_faces\\test\\Dart\\frame_0023_5458_body_face.jpg\n",
      "‚úÖ Masked face saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_faces\\test\\Dart\\frame_0026_5458_body_face.jpg\n",
      "‚úÖ Masked face saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_faces\\test\\Diamond T\\frame_0003_5401_body_face.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                                        | 25/80 [00:00<00:00, 76.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Masked face saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_faces\\test\\Diamond T\\frame_0012_5401_body_face.jpg\n",
      "‚úÖ Masked face saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_faces\\test\\Diamond T\\frame_0023_5401_body_face.jpg\n",
      "‚úÖ Masked face saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_faces\\test\\Fiat\\frame_0004_5413_body_face.jpg\n",
      "‚úÖ Masked face saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_faces\\test\\Fiat\\frame_0013_5459_body_face.jpg\n",
      "‚úÖ Masked face saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_faces\\test\\Fiat\\frame_0020_5459_body_face.jpg\n",
      "‚úÖ Masked face saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_faces\\test\\Fiat\\frame_0027_5413_body_face.jpg\n",
      "‚úÖ Masked face saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_faces\\test\\Fiat\\frame_0028_5413_body_face.jpg\n",
      "‚úÖ Masked face saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_faces\\test\\Freeman\\frame_0002_5468_body_face.jpg\n",
      "‚úÖ Masked face saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_faces\\test\\Freeman\\frame_0004_5380_body_face.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                               | 34/80 [00:00<00:00, 78.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Masked face saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_faces\\test\\Freeman\\frame_0008_5380_body_face.jpg\n",
      "‚úÖ Masked face saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_faces\\test\\Freeman\\frame_0010_5380_body_face.jpg\n",
      "‚úÖ Masked face saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_faces\\test\\Freeman\\frame_0012_5468_body_face.jpg\n",
      "‚úÖ Masked face saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_faces\\test\\Freeman\\frame_0015_5468_body_face.jpg\n",
      "‚úÖ Masked face saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_faces\\test\\Gersix\\frame_0000_5396_body_face.jpg\n",
      "‚úÖ Masked face saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_faces\\test\\Gersix\\frame_0009_5396_body_face.jpg\n",
      "‚úÖ Masked face saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_faces\\test\\Gersix\\frame_0011_5396_body_face.jpg\n",
      "‚úÖ Masked face saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_faces\\test\\Gersix\\frame_0022_5396_body_face.jpg\n",
      "‚úÖ Masked face saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_faces\\test\\Gersix\\frame_0024_5396_body_face.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                      | 43/80 [00:00<00:00, 79.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Masked face saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_faces\\test\\Hayes\\frame_0003_5392_body_face.jpg\n",
      "‚úÖ Masked face saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_faces\\test\\Hayes\\frame_0011_5392_body_face.jpg\n",
      "‚úÖ Masked face saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_faces\\test\\John Dere (Deere)\\frame_0000_5481_body_face.jpg\n",
      "‚úÖ Masked face saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_faces\\test\\John Dere (Deere)\\frame_0003_5481_body_face.jpg\n",
      "‚úÖ Masked face saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_faces\\test\\John Dere (Deere)\\frame_0004_5407_body_face.jpg\n",
      "‚úÖ Masked face saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_faces\\test\\John Dere (Deere)\\frame_0006_5407_body_face.jpg\n",
      "‚úÖ Masked face saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_faces\\test\\John Dere (Deere)\\frame_0007_5407_body_face.jpg\n",
      "‚úÖ Masked face saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_faces\\test\\John Dere (Deere)\\frame_0010_5407_body_face.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                            | 52/80 [00:00<00:00, 80.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Masked face saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_faces\\test\\John Dere (Deere)\\frame_0012_5481_body_face.jpg\n",
      "‚úÖ Masked face saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_faces\\test\\John Dere (Deere)\\frame_0033_5407_body_face.jpg\n",
      "‚úÖ Masked face saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_faces\\test\\Jowett\\frame_0001_5446_body_face.jpg\n",
      "‚úÖ Masked face saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_faces\\test\\Jowett\\frame_0002_5457_body_face.jpg\n",
      "‚úÖ Masked face saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_faces\\test\\Jowett\\frame_0003_5446_body_face.jpg\n",
      "‚úÖ Masked face saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_faces\\test\\Jowett\\frame_0007_5446_body_face.jpg\n",
      "‚úÖ Masked face saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_faces\\test\\Jowett\\frame_0024_5457_body_face.jpg\n",
      "‚úÖ Masked face saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_faces\\test\\Jowett\\frame_0034_5446_body_face.jpg\n",
      "‚úÖ Masked face saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_faces\\test\\Jowett\\frame_0043_5457_body_face.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                   | 61/80 [00:00<00:00, 80.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Masked face saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_faces\\test\\Komatsu\\frame_0006_5428_body_face.jpg\n",
      "‚úÖ Masked face saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_faces\\test\\Komatsu\\frame_0008_5428_body_face.jpg\n",
      "‚úÖ Masked face saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_faces\\test\\Komatsu\\frame_0010_5428_body_face.jpg\n",
      "‚úÖ Masked face saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_faces\\test\\Komatsu\\frame_0036_5428_body_face.jpg\n",
      "‚úÖ Masked face saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_faces\\test\\Komatsu\\frame_0037_5428_body_face.jpg\n",
      "‚úÖ Masked face saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_faces\\test\\Komatsu\\frame_0040_5428_body_face.jpg\n",
      "‚úÖ Masked face saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_faces\\test\\Manchester\\frame_0003_5467_body_face.jpg\n",
      "‚úÖ Masked face saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_faces\\test\\Maple Leaf\\frame_0000_5411_body_face.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä          | 70/80 [00:00<00:00, 81.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Masked face saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_faces\\test\\Maple Leaf\\frame_0006_5411_body_face.jpg\n",
      "‚úÖ Masked face saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_faces\\test\\Maple Leaf\\frame_0007_5411_body_face.jpg\n",
      "‚úÖ Masked face saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_faces\\test\\Maple Leaf\\frame_0016_5411_body_face.jpg\n",
      "‚úÖ Masked face saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_faces\\test\\Maple Leaf\\frame_0031_5411_body_face.jpg\n",
      "‚úÖ Masked face saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_faces\\test\\Maple Leaf\\frame_0033_5411_body_face.jpg\n",
      "‚úÖ Masked face saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_faces\\test\\Maple Leaf\\frame_0034_5411_body_face.jpg\n",
      "‚úÖ Masked face saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_faces\\test\\Maple Leaf\\frame_0039_5411_body_face.jpg\n",
      "‚úÖ Masked face saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_faces\\test\\Maple Leaf\\frame_0040_5411_body_face.jpg\n",
      "‚úÖ Masked face saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_faces\\test\\Maple Leaf\\frame_0042_5411_body_face.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 80/80 [00:01<00:00, 79.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Masked face saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_faces\\test\\Pacific\\frame_0000_5469_body_face.jpg\n",
      "‚úÖ Masked face saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_faces\\test\\Pacific\\frame_0017_5469_body_face.jpg\n",
      "‚úÖ Masked face saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_faces\\test\\Republic\\frame_0001_5480_body_face.jpg\n",
      "‚úÖ Masked face saved: D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\\masked_faces\\test\\Sentinel\\frame_0008_5474_body_face.jpg\n",
      "\n",
      "‚úÖ Masking process for test set completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "# ------------------------\n",
    "# CONFIGURATION\n",
    "# ------------------------\n",
    "OUTPUT_DIR = r\"D:\\Master's Research\\yolo+vos+arcface\\dataset_augmented1\"\n",
    "MASKS_DIR = os.path.join(OUTPUT_DIR, \"test\", \"masks\")  # Path to test set masks\n",
    "BODY_JSON_PATH = os.path.join(OUTPUT_DIR, \"test_body_face_bboxes.json\")  # Body bboxes\n",
    "FACE_JSON_PATH = os.path.join(OUTPUT_DIR, \"test_face_bboxes.json\")  # Face bboxes\n",
    "\n",
    "# Input directories (original cropped images)\n",
    "CROPPED_BODY_DIR = os.path.join(OUTPUT_DIR, \"cropped_bodies\", \"test\")\n",
    "CROPPED_FACE_DIR = os.path.join(OUTPUT_DIR, \"cropped_faces\", \"test\")\n",
    "\n",
    "# Output directories (masked images)\n",
    "MASKED_BODY_DIR = os.path.join(OUTPUT_DIR, \"masked_bodies\", \"test\")\n",
    "MASKED_FACE_DIR = os.path.join(OUTPUT_DIR, \"masked_faces\", \"test\")\n",
    "\n",
    "for folder in [MASKED_BODY_DIR, MASKED_FACE_DIR]:\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "# ------------------------\n",
    "# FUNCTION: Load Mask\n",
    "# ------------------------\n",
    "def load_mask(mask_path):\n",
    "    \"\"\"Loads a VOS mask as a binary numpy array.\"\"\"\n",
    "    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if mask is None:\n",
    "        print(f\"‚ö†Ô∏è Warning: Mask file missing {mask_path}\")\n",
    "        return None\n",
    "    return (mask > 0).astype(np.uint8)  # Convert to binary mask\n",
    "\n",
    "# ------------------------\n",
    "# FUNCTION: Apply Mask to Image\n",
    "# ------------------------\n",
    "def apply_mask(image, mask):\n",
    "    \"\"\"Applies a mask to an image, keeping only the masked regions.\"\"\"\n",
    "    if image.shape[:2] != mask.shape[:2]:  # Resize mask to match image size\n",
    "        mask = cv2.resize(mask, (image.shape[1], image.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "    masked_image = np.zeros_like(image)\n",
    "    masked_image[mask > 0] = image[mask > 0]\n",
    "    return masked_image\n",
    "\n",
    "# ------------------------\n",
    "# FUNCTION: Apply Mask to Cropped Bodies (Fixed)\n",
    "# ------------------------\n",
    "def apply_mask_to_bodies():\n",
    "    \"\"\"Applies VOS masks to test cropped bodies.\"\"\"\n",
    "    if not os.path.exists(BODY_JSON_PATH):\n",
    "        print(f\"‚ùå ERROR: Missing test body JSON: {BODY_JSON_PATH}\")\n",
    "        return\n",
    "\n",
    "    with open(BODY_JSON_PATH, 'r') as f:\n",
    "        body_detections = json.load(f)\n",
    "\n",
    "    for cropped_body_path, metadata in tqdm(body_detections.items()):\n",
    "        original_image_path = metadata[\"original_image\"]\n",
    "        bbox_body = metadata[\"bbox\"]\n",
    "\n",
    "        # Load cropped body image\n",
    "        body_image = cv2.imread(cropped_body_path)\n",
    "        if body_image is None:\n",
    "            print(f\"‚ùå Error loading {cropped_body_path}\")\n",
    "            continue\n",
    "\n",
    "        # Find corresponding mask (must match the original full image size)\n",
    "        mask_path = original_image_path.replace(\"images\", \"masks\").replace(\".jpg\", \".png\")\n",
    "        full_mask = load_mask(mask_path)\n",
    "        if full_mask is None:\n",
    "            continue\n",
    "\n",
    "        # Extract the body mask region from the full mask\n",
    "        x1, y1, x2, y2 = bbox_body\n",
    "        body_mask = full_mask[y1:y2, x1:x2]\n",
    "\n",
    "        if body_mask.shape[:2] != body_image.shape[:2]:  # Ensure mask matches cropped body\n",
    "            body_mask = cv2.resize(body_mask, (body_image.shape[1], body_image.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        # Apply mask to the cropped body\n",
    "        masked_body = apply_mask(body_image, body_mask)\n",
    "        if masked_body is None:\n",
    "            continue\n",
    "\n",
    "        # Save masked body\n",
    "        relative_body_path = os.path.relpath(cropped_body_path, CROPPED_BODY_DIR)\n",
    "        output_masked_body = os.path.join(MASKED_BODY_DIR, relative_body_path)\n",
    "        os.makedirs(os.path.dirname(output_masked_body), exist_ok=True)\n",
    "        cv2.imwrite(output_masked_body, masked_body)\n",
    "\n",
    "        print(f\"‚úÖ Masked body saved: {output_masked_body}\")\n",
    "\n",
    "# ------------------------\n",
    "# FUNCTION: Apply Mask to Cropped Faces (Working)\n",
    "# ------------------------\n",
    "def apply_mask_to_faces():\n",
    "    \"\"\"Applies VOS masks to test cropped faces.\"\"\"\n",
    "    if not os.path.exists(FACE_JSON_PATH):\n",
    "        print(f\"‚ùå ERROR: Missing test face JSON: {FACE_JSON_PATH}\")\n",
    "        return\n",
    "\n",
    "    with open(FACE_JSON_PATH, 'r') as f:\n",
    "        face_detections = json.load(f)\n",
    "\n",
    "    for cropped_face_path, metadata in tqdm(face_detections.items()):\n",
    "        original_image_path = metadata[\"original_image\"]\n",
    "        bbox_face = metadata[\"bbox_face\"]\n",
    "\n",
    "        # Load cropped face image\n",
    "        face_image = cv2.imread(cropped_face_path)\n",
    "        if face_image is None:\n",
    "            print(f\"‚ùå Error loading {cropped_face_path}\")\n",
    "            continue\n",
    "\n",
    "        # Find corresponding mask\n",
    "        mask_path = original_image_path.replace(\"images\", \"masks\").replace(\".jpg\", \".png\")\n",
    "        full_mask = load_mask(mask_path)\n",
    "        if full_mask is None:\n",
    "            continue\n",
    "\n",
    "        # Extract face region mask from full mask\n",
    "        x1, y1, x2, y2 = bbox_face\n",
    "        mask_face = full_mask[y1:y2, x1:x2]\n",
    "\n",
    "        if mask_face.shape[:2] != face_image.shape[:2]:  # Resize mask if needed\n",
    "            mask_face = cv2.resize(mask_face, (face_image.shape[1], face_image.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        # Apply mask to the cropped face\n",
    "        masked_face = apply_mask(face_image, mask_face)\n",
    "        if masked_face is None:\n",
    "            continue\n",
    "\n",
    "        # Save masked face\n",
    "        relative_face_path = os.path.relpath(cropped_face_path, CROPPED_FACE_DIR)\n",
    "        output_masked_face = os.path.join(MASKED_FACE_DIR, relative_face_path)\n",
    "        os.makedirs(os.path.dirname(output_masked_face), exist_ok=True)\n",
    "        cv2.imwrite(output_masked_face, masked_face)\n",
    "\n",
    "        print(f\"‚úÖ Masked face saved: {output_masked_face}\")\n",
    "\n",
    "# ------------------------\n",
    "# EXECUTION\n",
    "# ------------------------\n",
    "print(\"\\nüîç Applying VOS masks to cropped bodies...\")\n",
    "apply_mask_to_bodies()\n",
    "\n",
    "print(\"\\nüîç Applying VOS masks to cropped faces...\")\n",
    "apply_mask_to_faces()\n",
    "\n",
    "print(\"\\n‚úÖ Masking process for test set completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ba0e6e-54ec-4771-97e7-e40d2b864540",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (yolov7_env)",
   "language": "python",
   "name": "yolov7_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
